<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="IPython Cookbook, ">


    <!-- FAVICON -->
    <link rel="apple-touch-icon" sizes="57x57" href="/apple-touch-icon-57x57.png">
    <link rel="apple-touch-icon" sizes="114x114" href="/apple-touch-icon-114x114.png">
    <link rel="apple-touch-icon" sizes="72x72" href="/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon-144x144.png">
    <link rel="apple-touch-icon" sizes="60x60" href="/apple-touch-icon-60x60.png">
    <link rel="apple-touch-icon" sizes="120x120" href="/apple-touch-icon-120x120.png">
    <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon-76x76.png">
    <link rel="apple-touch-icon" sizes="152x152" href="/apple-touch-icon-152x152.png">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon-180x180.png">
    <link rel="icon" type="image/png" href="/favicon-192x192.png" sizes="192x192">
    <link rel="icon" type="image/png" href="/favicon-160x160.png" sizes="160x160">
    <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96">
    <link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
    <link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-TileImage" content="/mstile-144x144.png">


        <link rel="alternate"  href="http://ipython-books.github.io/feeds/all.atom.xml" type="application/atom+xml" title="IPython Cookbook Full Atom Feed"/>

        <title>IPython Cookbook - 8.2. Predicting who will survive on the Titanic with logistic regression</title>

    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.3.0/pure-min.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.5.0/grids-responsive-old-ie-min.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.5.0/grids-responsive-min.css">
    <!--<![endif]-->
    <link rel="stylesheet" href="http://ipython-books.github.io/theme/css/styles.css">
    <link rel="stylesheet" href="http://ipython-books.github.io/theme/css/pygments.css">
    <!-- <link href='http://fonts.googleapis.com/css?family=Lato:300,400,700' rel='stylesheet' type='text/css'> -->
    <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,500" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Ubuntu+Mono' rel='stylesheet' type='text/css'>
    

    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
</head>

<body>


    <header id="header" class="pure-g">
        <div class="pure-u-1 pure-u-md-3-4">
             <div id="menu">
                 <div class="pure-menu pure-menu-open pure-menu-horizontal">
<ul>
        <li><a href="/">home</a></li>
        <li><a href="https://github.com/ipython-books/cookbook-2nd-code">Jupyter notebooks</a></li>
        <li><a href="https://github.com/ipython-books/minibook-2nd-code">minibook</a></li>
        <li><a href="http://cyrille.rossant.net">author</a></li>
</ul>                </div>
            </div>
        </div>

        <div class="pure-u-1 pure-u-md-1-4">
            <div id="social">
                <div class="pure-menu pure-menu-open pure-menu-horizontal">
<ul>
        <li><a href="https://twitter.com/cyrillerossant"><i class="fa fa-twitter"></i></a></li>
        <li><a href="https://github.com/ipython-books/cookbook-2nd"><i class="fa fa-github"></i></a></li>
</ul>                </div>
            </div>
        </div>
    </header>
       

    
    <div id="layout" class="pure-g">
        <section id="content" class="pure-u-1 pure-u-md-4-4">
            <div class="l-box">

    <header id="page-header">
        <h1>8.2. Predicting who will survive on the Titanic with logistic regression</h1>
    </header>

    <section id="page">
        <p><a href="/"><img src="https://raw.githubusercontent.com/ipython-books/cookbook-2nd/master/cover-cookbook-2nd.png" align="left" alt="IPython Cookbook, Second Edition" height="130" style="margin-right: 20px; margin-bottom: 10px;" /></a> <em>This is one of the 100+ free recipes of the <a href="/">IPython Cookbook, Second Edition</a>, by <a href="http://cyrille.rossant.net">Cyrille Rossant</a>, a guide to numerical computing and data science in the Jupyter Notebook. The ebook and printed book are available for purchase at <a href="https://www.packtpub.com/big-data-and-business-intelligence/ipython-interactive-computing-and-visualization-cookbook-second-e">Packt Publishing</a>.</em></p>
<p>▶&nbsp;&nbsp;<em><a href="https://github.com/ipython-books/cookbook-2nd">Text on GitHub</a> with a <a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode">CC-BY-NC-ND license</a></em><br />
▶&nbsp;&nbsp;<em><a href="https://github.com/ipython-books/cookbook-2nd-code">Code on GitHub</a> with a <a href="https://opensource.org/licenses/MIT">MIT license</a></em></p>
<p>▶&nbsp;&nbsp;<a href="http://ipython-books.github.io/chapter-8-machine-learning/"><strong><em>Go to</em></strong> <em>Chapter 8 : Machine Learning</em></a><br />
▶&nbsp;&nbsp;<a href="https://github.com/ipython-books/cookbook-2nd-code/blob/master/chapter08_ml/02_titanic.ipynb"><em><strong>Get</strong> the Jupyter notebook</em></a>  </p>
<p>In this recipe, we will introduce <strong>logistic regression</strong>, a basic classifier. We will apply these techniques on a <strong>Kaggle</strong> dataset where the goal is to predict survival on the Titanic based on real data (see <a href="http://www.kaggle.com/c/titanic">http://www.kaggle.com/c/titanic</a>).</p>
<blockquote>
<p>Kaggle (http://www.kaggle.com/competitions) hosts machine learning competitions where anyone can download a dataset, train a model, and test the predictions on the website.</p>
</blockquote>
<h2>How to do it...</h2>
<p><strong>1.&nbsp;</strong> We import the standard packages:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="kn">as</span> <span class="nn">lm</span>
<span class="kn">import</span> <span class="nn">sklearn.model_selection</span> <span class="kn">as</span> <span class="nn">ms</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>
</div>


<p><strong>2.&nbsp;</strong> We load the training and test datasets with pandas:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://github.com/ipython-books&#39;</span>
                    <span class="s1">&#39;/cookbook-2nd-data/blob/master/&#39;</span>
                    <span class="s1">&#39;titanic_train.csv?raw=true&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;https://github.com/ipython-books/&#39;</span>
                   <span class="s1">&#39;cookbook-2nd-data/blob/master/&#39;</span>
                   <span class="s1">&#39;titanic_test.csv?raw=true&#39;</span><span class="p">)</span>
</pre></div>
</div>


<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>


<p><img alt="Output" src="http://ipython-books.github.io/pages/chapter08_ml/02_titanic_files/02_titanic_8_0.png" /></p>
<p><strong>3.&nbsp;</strong> Let's keep only a few fields for this example, and also convert the <code>sex</code> field to a binary variable so that it can be handled correctly by NumPy and scikit-learn. Finally, we remove the rows that contain <code>NaN</code> values:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">train</span><span class="p">[[</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;Pclass&#39;</span><span class="p">,</span> <span class="s1">&#39;Survived&#39;</span><span class="p">]]</span>
<span class="c1"># Add a &#39;Female&#39; column.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">Female</span><span class="o">=</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;Sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;female&#39;</span><span class="p">)</span>
<span class="c1"># Reorder the columns.</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span> <span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;Pclass&#39;</span><span class="p">,</span> <span class="s1">&#39;Survived&#39;</span><span class="p">]]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>


<p><img alt="Output" src="http://ipython-books.github.io/pages/chapter08_ml/02_titanic_files/02_titanic_10_0.png" /></p>
<p><strong>4.&nbsp;</strong> Now, we convert this <code>DataFrame</code> object to a NumPy array so that we can pass it to scikit-learn:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="n">data_np</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data_np</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data_np</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>


<p><strong>5.&nbsp;</strong> Let's have a look at the survival of male and female passengers as a function of their age:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="c1"># We define a few boolean vectors.</span>
<span class="c1"># The first column is &#39;Female&#39;.</span>
<span class="n">female</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>

<span class="c1"># The last column is &#39;Survived&#39;.</span>
<span class="n">survived</span> <span class="o">=</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">1</span>

<span class="c1"># This vector contains the age of the passengers.</span>
<span class="n">age</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># We compute a few histograms.</span>
<span class="n">bins_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">81</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">S</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;male&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">age</span><span class="p">[</span><span class="n">survived</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">female</span><span class="p">],</span>
                          <span class="n">bins</span><span class="o">=</span><span class="n">bins_</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
     <span class="s1">&#39;female&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">age</span><span class="p">[</span><span class="n">survived</span> <span class="o">&amp;</span> <span class="n">female</span><span class="p">],</span>
                            <span class="n">bins</span><span class="o">=</span><span class="n">bins_</span><span class="p">)[</span><span class="mi">0</span><span class="p">]}</span>
<span class="n">D</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;male&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">age</span><span class="p">[</span><span class="o">~</span><span class="n">survived</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">female</span><span class="p">],</span>
                          <span class="n">bins</span><span class="o">=</span><span class="n">bins_</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>
     <span class="s1">&#39;female&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">age</span><span class="p">[</span><span class="o">~</span><span class="n">survived</span> <span class="o">&amp;</span> <span class="n">female</span><span class="p">],</span>
                            <span class="n">bins</span><span class="o">=</span><span class="n">bins_</span><span class="p">)[</span><span class="mi">0</span><span class="p">]}</span>
</pre></div>
</div>


<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="c1"># We now plot the data.</span>
<span class="n">bins</span> <span class="o">=</span> <span class="n">bins_</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                         <span class="n">sharey</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">sex</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">),</span>
                          <span class="p">(</span><span class="s1">&#39;#3345d0&#39;</span><span class="p">,</span> <span class="s1">&#39;#cc3dc0&#39;</span><span class="p">)):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">S</span><span class="p">[</span><span class="n">sex</span><span class="p">],</span> <span class="n">bottom</span><span class="o">=</span><span class="n">D</span><span class="p">[</span><span class="n">sex</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span>
           <span class="n">width</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;survived&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">D</span><span class="p">[</span><span class="n">sex</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span>
           <span class="n">width</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;died&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Age (years)&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">sex</span> <span class="o">+</span> <span class="s2">&quot; survival&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">None</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>


<p><img alt="&lt;matplotlib.figure.Figure at 0x5adbda0&gt;" src="http://ipython-books.github.io/pages/chapter08_ml/02_titanic_files/02_titanic_15_0.png" /></p>
<p><strong>6.&nbsp;</strong> Let's try to train a <code>LogisticRegression</code> classifier in order to predict the survival of people based on their gender, age, and class. We first need to create a train and a test dataset:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="c1"># We split X and y into train and test datasets.</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> \
    <span class="n">ms</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=.</span><span class="mo">05</span><span class="p">)</span>
</pre></div>
</div>


<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="c1"># We instanciate the classifier.</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span>
</pre></div>
</div>


<p><strong>7.&nbsp;</strong> We train the model and we get the predicted values on the test set:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="n">logreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_predicted</span> <span class="o">=</span> <span class="n">logreg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>


<p>The following figure shows the actual and predicted results:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_predicted</span><span class="p">)),</span>
          <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;bone&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Actual and predicted survival outcomes &quot;</span>
             <span class="s2">&quot;on the test set&quot;</span><span class="p">)</span>
</pre></div>
</div>


<p><img alt="&lt;matplotlib.figure.Figure at 0x8f5d160&gt;" src="http://ipython-books.github.io/pages/chapter08_ml/02_titanic_files/02_titanic_22_0.png" /></p>
<p><strong>8.&nbsp;</strong> To get an estimation of the model's performance, we compute the cross-validation score with the <code>cross_val_score()</code> function. This function uses a three-fold stratified cross-validation procedure by default, but this can be changed with the <code>cv</code> keyword argument:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="n">ms</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>


<div class="highlight highlight-text"><div class="highlight"><pre><span></span>array([ 0.78661088,  0.78991597,  0.78059072])
</pre></div>
</div>


<p>This function returns, for each pair of train and test set, a prediction score (we give more details in <em>How it works...</em>).</p>
<p><strong>9.&nbsp;</strong> The <code>LogisticRegression</code> class accepts a <code>C</code> hyperparameter as an argument. This parameter quantifies the regularization strength. To find a good value, we can perform a grid search with the generic <code>GridSearchCV</code> class. It takes an estimator as input and a dictionary of parameter values. We can also specify the number of cores to use on a multicore processor with the <code>n_jobs</code> argument. This new estimator uses cross-validation to select the best parameter:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span>
    <span class="n">logreg</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">200</span><span class="p">)},</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>


<div class="highlight highlight-text"><div class="highlight"><pre><span></span>{&#39;C&#39;: 0.042}
</pre></div>
</div>


<p><strong>10.&nbsp;</strong> Here is the performance of the best estimator:</p>
<div class="highlight highlight-python"><div class="highlight"><pre><span></span><span class="n">ms</span><span class="o">.</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>


<div class="highlight highlight-text"><div class="highlight"><pre><span></span>array([ 0.77405858,  0.80672269,  0.78902954])
</pre></div>
</div>


<h2>How it works...</h2>
<p>Logistic regression is <em>not</em> a regression model, it is a classification model. Yet, it is closely related to linear regression. This model predicts the probability that a binary variable is 1, by applying a <strong>sigmoid function</strong> (more precisely, a logistic function) to a linear combination of the variables. The equation of the sigmoid is:</p>
<div class="math">$$\forall i \in \{1, \ldots, N\}, \quad \mathbf{\hat{y}}_i = f(\mathbf{x}_i \mathbf{w}) \quad \textrm{where} \quad f(x) = \frac{1}{1+\exp(-x)}.$$</div>
<p>The following figure shows a logistic function:</p>
<p><img alt="A logistic function" src="http://ipython-books.github.io/pages/chapter08_ml/02_titanic_files/logit.png" /></p>
<p>If a binary variable has to be obtained, we can round the value to the closest integer.</p>
<p>The parameter <code>w</code> is obtained with an optimization procedure during the learning step.</p>
<h2>There's more...</h2>
<p>Here are a few references:</p>
<ul>
<li>Logistic regression in scikit-learn's documentation, available at <a href="http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression">http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression</a></li>
<li>Logistic regression on Wikipedia, available at <a href="https://en.wikipedia.org/wiki/Logistic_regression">https://en.wikipedia.org/wiki/Logistic_regression</a></li>
</ul>
<h2>See also</h2>
<ul>
<li>Geting started with scikit-learn</li>
<li>Learning to recognize handwritten digits with a K-nearest neighbors classifier</li>
<li>Using support vector machines for classification tasks</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
    </section>

            </div>
        </section>

        <footer id="footer" class="pure-u-1 pure-u-md-4-4">
            <div class="l-box">
                <div>
                    <p>&copy; <a href="http://cyrille.rossant.net">Cyrille Rossant</a> &ndash;
                        Built with <a href="https://github.com/PurePelicanTheme/pure-single">Pure Theme</a>
                        for <a href="http://blog.getpelican.com/">Pelican</a>
                    </p>
                </div>
            </div>
        </footer>
        
    </div>
    
<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=9752080; 
var sc_invisible=1; 
var sc_security="c177b501"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="//c.statcounter.com/9752080/0/c177b501/1/" alt="Web
Analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
</body>
</html>

